---
title: "Prostate cancer recurrence risk Prediction"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    theme: "cerulean"
    source_code: embed
runtime: shiny
---

```{r global, include=FALSE}
pacman::p_load(
    dplyr,
    tidyverse,
    flexdashboard,
    plotly,
    summarytools,
    prettycode,
    lmerTest,
    ggridges,
    DT,
    ggeffects,
    splines,
    ggiraphExtra,
    ggplot2,
    ResourceSelection,
    pscl,
    DALEX,
    DALEXtra,
    tidymodels,
    pROC,
    vip,
    jtools,
    devtools
)
# import data
load(file = "pheno.mir.rna1.rda")

final_dat <- pheno.mir.rna1


```

# Exploratory Data Analysis
Inputs {.sidebar}
-----------------------------------------------------------------------
**Exploratory Data Analysis**\

Explore relationships between features and the outcome 
```{r}
# separate factors and numeric variables
var_factor <- final_dat %>% 
  select_if(is.factor)
var_factor <- colnames(var_factor)
var_numeric <- final_dat %>% 
  select_if(is.numeric)
var_numeric <- colnames(var_numeric[-1])
# shiny app input numeric
selectInput("x", label = "X", names(final_dat))
selectInput("y", label = "Y", c("none", names(final_dat)), names(final_dat)[[2]])
selectInput("color", "Color by group", c("none", var_factor))
```


App author: Briha Ansari, MD

Row
-----------------------------------------------------------------------
### Total N
```{r}
total <- nrow(final_dat)
valueBox(total, "Total N", icon = "ion-android-contact")
```

### Median Gleason Score
```{r}
Gleason_Score <- 7
valueBox(Gleason_Score, "Median Gleason Score", 
         #icon = "ion-android-stopwatch",
         color = "success")
```

### % Recurrence
```{r}
valueBox(scales::percent(.178), 
         "Recurrence", 
         #icon = "ion-battery-low", 
         color = "warning")
```

Row
-----------------------------------------------------------------------
### Plot

```{r}
# get plot type
# 2 = both numeric
# 1 = one numeric, one non-numeric
# 0 = both non-numeric
# -1 = only one variable
plot_type <- reactive({
  if(input$y != "none")
    is.numeric(final_dat[[input$x]]) + is.numeric(final_dat[[input$y]])
  else
    -1
})
renderPlot({
  if (plot_type() ==2) {
    # 2 num = scatterplot
    p <- ggplot(final_dat, aes_string(input$x, input$y)) +
      geom_point(alpha = 0.5) +
      geom_smooth()
    # color change
    if (input$color != "none")
      p <- p + aes_string(color = input$color)
  } else if (plot_type() == 1) {
    # 1 num, 1 non-num = boxplot
    p <- ggplot(final_dat, aes_string(input$x, input$y)) +
      geom_boxplot()
    
    # fill change
    if (input$color != "none")
      p <- p + aes_string(fill = input$color)
  } 
  else if (plot_type() == 0 ) {
    # 2 non-num = heatmap
    temp_dat <- reactive(final_dat[, c(input$x, input$y)] %>% 
                           group_by(across()) %>% 
                           summarize(proportion = n()/length(final_dat$recurrence))
                         )
    p <- ggplot(temp_dat(),
                mapping = aes_string(x = input$x, y = input$y, fill = "proportion")) +
      geom_tile()
  } else {
    # 1 var only = univariate plot
    p <- ggplot(final_dat, aes_string(x = input$x))
    
    if(is.numeric(final_dat[[input$x]]))
      p <- p + geom_histogram()
    else
      p <- p + geom_bar(aes(y=..prop..),stat="counts")
    
    # fill change
    if(input$color != "none")
      p <- p + aes_string(fill = input$color)
  }
  
  # add title
  if(plot_type() >= 0) {
    p <- p + labs(title = paste(input$y, "vs.", input$x))
  } else {
    p <- p + labs(title = paste("Distribution of", input$x))
  }
  
  # add styling
  p <- p +
    theme_bw() +
    theme(plot.title = element_text(size = rel(1.8), face = "bold", hjust = 0.5),
          axis.title = element_text(size = rel(1.2)))
  print(p)
})

#Reference: Jae Hyoung Tim Lee (JHSPH,MPH student)

```

# Logistic Regression (L2)

```{r load regularized regression model & data}
log_reg <- readRDS("final_lr_wf.RDS")
```


```{r explainable, include=FALSE}
log_reg_trained <- log_reg %>%
  fit(data = final_dat)
log_reg_explainer <- explain_tidymodels(
  model = log_reg_trained,
  data = final_dat %>%
    select(-recurrence),
  y = final_dat$recurrence,
  label = "Regularized Logistic Regression")
```

Inputs {.sidebar}
-----------------------------------------------------------------------

Select the feature value to view the probability of recurrence 

```{r}
sliderInput(inputId = "Gleason_Score_I", label = "Gleason_Score",
            min = 6,
            max = max(final_dat$gleason_score),
            value = 7)
sliderInput(inputId = "loc440173_I", label = "loc440173",
            min = 0,
            max = 383,
            value = 15)
sliderInput(inputId = "fam36a_I", label = "fam36a",
            min = 499,
            max = 3400,
            value = 1129)

```

Other Variables are set to zero


```{r}



  





log_reg_obs <- reactive({tibble(
  
gleason_score = input$Gleason_Score_I,
loc440173 = input$loc440173_I,
fam36a = input$fam36a_I,
hsa_mir_1252 = mean(final_dat$hsa_mir_1252),             
hsa_mir_340 = mean(final_dat$hsa_mir_340),
hsa_mir_145 = mean(final_dat$hsa_mir_145),    
hsa_mir_326 = mean(final_dat$hsa_mir_326),   
hsa_mir_320b_2 = mean(final_dat$hsa_mir_320b_2),
hsa_mir_4326  = mean(final_dat$hsa_mir_4326), 
hsa_mir_548b  = mean(final_dat$hsa_mir_548b), 
hsa_mir_125b_1 = mean(final_dat$hsa_mir_125b_1),
hsa_mir_132 = mean(final_dat$hsa_mir_132),  
hsa_mir_205 = mean(final_dat$hsa_mir_205),   
hsa_mir_212 = mean(final_dat$hsa_mir_212),   
hsa_mir_23b = mean(final_dat$hsa_mir_23b),   
hsa_mir_24_1  = mean(final_dat$hsa_mir_24_1), 
hsa_mir_320a  = mean(final_dat$hsa_mir_320a),
hsa_mir_328   = mean(final_dat$hsa_mir_328), 
hsa_mir_34a  = mean(final_dat$hsa_mir_34a),
hsa_mir_376a_1 = mean(final_dat$hsa_mir_376a_1),
hsa_mir_377 = mean(final_dat$hsa_mir_377),
hsa_mir_378 = mean(final_dat$hsa_mir_378),   
hsa_mir_3909 = mean(final_dat$hsa_mir_3909),        
stxbp6 = mean(final_dat$stxbp6),         
znf467 = mean(final_dat$znf467),         
rgpd5  = mean(final_dat$rgpd5),        
fcgr2a = mean(final_dat$fcgr2a),       
prr13 = mean(final_dat$prr13),         
cenpe = mean(final_dat$cenpe),          
nptx2 = mean(final_dat$nptx2),         
kbtbd3 = mean(final_dat$kbtbd3),         
fuca2  = mean(final_dat$fuca2),        
c11orf1 = mean(final_dat$c11orf1),       
pax9 = mean(final_dat$pax9),           
spns1 = mean(final_dat$spns1),          
hist1h2ac = mean(final_dat$hist1h2ac),    
adamts7 = mean(final_dat$adamts7),       
znrf3 = mean(final_dat$znrf3),         
sh3bgrl2 = mean(final_dat$sh3bgrl2),       
c16orf59 = mean(final_dat$c16orf59),       
cdh24 = mean(final_dat$cdh24),         
eda2r = mean(final_dat$eda2r),         
pcdhga10 = mean(final_dat$pcdhga10),      
golga3 = mean(final_dat$golga3),        
il12a = mean(final_dat$il12a),         
alg1l2 = mean(final_dat$alg1l2),         
nup43 = mean(final_dat$nup43),         
or52n2 = mean(final_dat$or52n2),        
trh = mean(final_dat$trh),           
dgat2l6 = mean(final_dat$dgat2l6),       
sema6b = mean(final_dat$sema6b),         
prox2 = mean(final_dat$prox2),        
ddx31 = mean(final_dat$ddx31),         
fam133b = mean(final_dat$fam133b),       
ncrna00230b = mean(final_dat$ncrna00230b), 
loc642852=mean(final_dat$loc642852),
prrt3 = mean(final_dat$prrt3))})
                               
                                
                                
                                
                                
                                
                                
                                
                                
                  






prob1 <- reactive({predict(log_reg_explainer, newdata = log_reg_obs())})
```


Row {data-height=450}
-----------------------------------------------------------------------
### Probability of Prostate Cancer recurrence

```{r}
renderValueBox({
  valueBox(value = scales::percent(round(prob1(),2)),
           "Probability of recurrence",
           color = "warning")
})
```

### Break down profile
```{r}
renderPlotly({
  plot(predict_parts_break_down(explainer = log_reg_explainer,
                                new_observation = log_reg_obs()))
})
```

Row {data-height=450}
-----------------------------------------------------------------------
### Feature Importance Plot
```{r}
vimp1 <- model_parts(log_reg_explainer)
renderPlotly({
  plot(vimp1)
})
```


```{r}
auc1 <- log_reg_trained %>%
  predict(new_data = final_dat, type = "prob") %>%
  bind_cols(truth = final_dat$recurrence) %>%
  roc_auc(truth = truth, estimate = .pred_no) %>% 
  pull(.estimate) %>% 
  round(digits=2)
```

### AUC
```{r}
log_reg_trained %>%
  predict(new_data = final_dat, type = "prob") %>%
  bind_cols(truth = final_dat$recurrence) %>%
  roc_curve(truth = truth, estimate = .pred_no) %>% 
  autoplot() +
  annotate("text", label = auc1, x = 0.25, y = 0.5 )
```



# About
______________________________________________________________

This is a pilot app, after further improvement, we expect that this app will assist oncologists in quantifying recurrence risk of prostate cancer and facilitate concrete risk communication between physician and patients.

MOtIA (MultiOmics Integration App), a shiny web app provides a graphical user interface (GUI) to a tidy model logistic regression (L2) workflow in the back end and reacts to user inputs.
The first tab allows the user to explore relationships between features and the outcome (Figure 5). The second tab displays four panels, the top two panels react to user input and show local predictions in terms of probability and demonstrates a breakdown showing the magnitude of each featureâ€™s contribution to the total predicted probability (Figure 6). The lower two panels show the feature importance plots and AUC of the logistic regression (L2) model used.


**References**

Adapted from Briha Ansari. F-CL, Tim Lee. App to predict probability of problem falling asleep. (https://github.com/BriAnsari/NHANES).
                                                            

**Disclaimer**
This app is created for an MPH capstone project and is NOT validated. If you have any concerns relating to the recurrence risk of prostate cancer, please consult a healthcare provider. This app does not reflect the views of the Johns Hopkins University, the Johns Hopkins Hospital, or any of their affiliates

**Authors**
Briha Ansari, MD.

**Last modified**
7/27/2021
